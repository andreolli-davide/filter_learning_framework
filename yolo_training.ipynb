{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ðŸŽ¯ YOLO Training with Custom Data Augmentation\n",
        "\n",
        "This notebook trains a YOLO model for malaria detection with **custom filter-based data augmentation**.\n",
        "\n",
        "**Features:**\n",
        "- Interactive configuration with widgets\n",
        "- Custom data augmentation pipeline using image filters\n",
        "- Support for multiple YOLO versions (v3, v5, v8, etc.)\n",
        "- Automated training and testing workflow\n",
        "\n",
        "> ðŸ“š For more information: [filter_learning_framework](https://github.com/andreolli-davide/filter_learning_framework)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZTlshZD2Kel1"
      },
      "source": [
        "## 1. Setup\n",
        "Install required dependencies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ZNYSoHmqBFfM",
        "outputId": "2012a941-4c9d-4e20-ad91-e2726b4d1185"
      },
      "outputs": [],
      "source": [
        "%pip install ultralytics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBAapCI6kx1l"
      },
      "source": [
        "## 2. Configuration\n",
        "Configure training options using interactive widgets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Nw7oz1N0ral"
      },
      "outputs": [],
      "source": [
        "from ipywidgets import widgets\n",
        "\n",
        "data_augmentation = widgets.Checkbox(\n",
        "    value=True, description=\"Apply data augmentation\", disabled=False\n",
        ")\n",
        "\n",
        "display(data_augmentation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gV22fd_U_vTo"
      },
      "source": [
        "## 3. Load Dataset\n",
        "Download and load the malaria detection dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w7rlnbD_3lfq",
        "outputId": "d83fdd7f-f993-4a8a-826f-d8c5d60a663a"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import kagglehub\n",
        "from src.dataset import Dataset\n",
        "\n",
        "DATASET_PATH: Path = Path(\"resources/dataset\")\n",
        "\n",
        "if not DATASET_PATH or not DATASET_PATH.exists():\n",
        "    dataset_path = Path(\n",
        "        kagglehub.dataset_download(\n",
        "            \"davidesenette/malaria-hcm-lcm-1000\",\n",
        "        )\n",
        "    )\n",
        "dataset = Dataset.load_from_directory(DATASET_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZ6pHMWejxdB"
      },
      "source": [
        "## 4. Prepare YOLO Configuration\n",
        "Generate YAML configuration file for YOLO training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2fmt4TPdugEK",
        "outputId": "206187c5-0f3e-4a6c-e000-774ccf18a55e"
      },
      "outputs": [],
      "source": [
        "from src.yolo import YoloConfig\n",
        "\n",
        "# Create YOLO configuration pointing to HCM (source) images\n",
        "config = YoloConfig(path=dataset.base_path / \"source\")\n",
        "config_path = config.store_yaml()\n",
        "\n",
        "print(f\"YOLO config saved to: {config_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSltw43GTCmk"
      },
      "source": [
        "## 5. Custom Data Augmentation\n",
        "Implement custom filter-based data augmentation for YOLO training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29BmguC3TTIm"
      },
      "source": [
        "### 5.1 Random Hyperparameter Generator\n",
        "Function to randomly select filter hyperparameters within valid ranges."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.2 Custom YOLO Dataset with Filter Augmentation\n",
        "Custom dataset class that applies random filter combinations during training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ydw1rf5qTB2I"
      },
      "outputs": [],
      "source": [
        "from src.filters import FilterParametersHint\n",
        "from ultralytics.data import YOLODataset\n",
        "import random\n",
        "\n",
        "\n",
        "def choose_random_hyperparameters(filters_list):\n",
        "    \"\"\"\n",
        "    Generate random hyperparameters for a list of filters.\n",
        "\n",
        "    Args:\n",
        "        filters_list: List of filter adapter classes\n",
        "\n",
        "    Returns:\n",
        "        List of filter parameter instances with randomized values\n",
        "    \"\"\"\n",
        "    hyperparameters = []\n",
        "\n",
        "    for filter_class in filters_list:\n",
        "        filter_parameters_class = filter_class.parameters_class\n",
        "        filter_suggested_parameters = {}\n",
        "\n",
        "        # Iterate over each hyperparameter field in the filter's parameter class\n",
        "        for field_name, field_info in filter_parameters_class.model_fields.items():\n",
        "            field_type = field_info.annotation\n",
        "            type_hints = filter_parameters_class.__annotations__[field_name]\n",
        "\n",
        "            # Extract hyperparameter hints from type metadata\n",
        "            for field_hint in type_hints.__metadata__:\n",
        "                if isinstance(field_hint, FilterParametersHint):\n",
        "                    # Generate random integer hyperparameters\n",
        "                    if field_type is int:\n",
        "                        step = field_hint.step if field_hint.step is not None else 1\n",
        "                        values = range(\n",
        "                            field_hint.lower_bound, field_hint.upper_bound + 1, step\n",
        "                        )\n",
        "                        filter_suggested_parameters[field_name] = random.choice(\n",
        "                            list(values)\n",
        "                        )\n",
        "\n",
        "                    # Generate random float hyperparameters\n",
        "                    elif field_type is float:\n",
        "                        if field_hint.step is not None:\n",
        "                            # Discrete float (with step)\n",
        "                            num_steps = (\n",
        "                                int(\n",
        "                                    (field_hint.upper_bound - field_hint.lower_bound)\n",
        "                                    / field_hint.step\n",
        "                                )\n",
        "                                + 1\n",
        "                            )\n",
        "                            values = [\n",
        "                                field_hint.lower_bound + i * field_hint.step\n",
        "                                for i in range(num_steps)\n",
        "                            ]\n",
        "                            filter_suggested_parameters[field_name] = random.choice(\n",
        "                                values\n",
        "                            )\n",
        "                        else:\n",
        "                            # Continuous float (without step)\n",
        "                            filter_suggested_parameters[field_name] = random.uniform(\n",
        "                                field_hint.lower_bound, field_hint.upper_bound\n",
        "                            )\n",
        "\n",
        "        # Store the suggested parameters for this filter\n",
        "        hyperparameters.append(\n",
        "            filter_class.parameters_class(**filter_suggested_parameters)\n",
        "        )\n",
        "\n",
        "    return hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vvo76IWvTe0I"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from src.filters import (\n",
        "    NoOpFilterAdapter,\n",
        "    MedianBlurFilterAdapter,\n",
        "    BilateralFilterAdapter,\n",
        "    SaturationBoostFilterAdapter,\n",
        "    ClaheFilterAdapter,\n",
        "    GammaCorrectionFilterAdapter,\n",
        "    UnsharpMaskFilterAdapter,\n",
        "    LaplacianSharpenFilterAdapter,\n",
        ")\n",
        "\n",
        "\n",
        "class YOLODatasetCustomDA(YOLODataset):\n",
        "    \"\"\"\n",
        "    Custom YOLO dataset with filter-based data augmentation.\n",
        "\n",
        "    Applies random filter combinations during training to augment images.\n",
        "    Filter layers:\n",
        "    1. Noise Reduction: NoOp, MedianBlur, BilateralFilter\n",
        "    2. Color Correction: NoOp, SaturationBoost\n",
        "    3. Contrast Enhancement: NoOp, CLAHE, GammaCorrection\n",
        "    4. Edge Sharpening: NoOp, UnsharpMask, LaplacianSharpen\n",
        "    \"\"\"\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # Get sample from parent dataset\n",
        "        sample = super().__getitem__(index)\n",
        "\n",
        "        # Get the image as a PyTorch tensor (CHW format)\n",
        "        img_tensor = sample[\"img\"]\n",
        "\n",
        "        # Convert to NumPy HWC format for filter application\n",
        "        img_numpy = img_tensor.permute(1, 2, 0).cpu().numpy()\n",
        "\n",
        "        # Define filter layers (one filter randomly selected per layer)\n",
        "        filter_layers = [\n",
        "            [NoOpFilterAdapter, MedianBlurFilterAdapter, BilateralFilterAdapter],\n",
        "            [NoOpFilterAdapter, SaturationBoostFilterAdapter],\n",
        "            [NoOpFilterAdapter, ClaheFilterAdapter, GammaCorrectionFilterAdapter],\n",
        "            [\n",
        "                NoOpFilterAdapter,\n",
        "                UnsharpMaskFilterAdapter,\n",
        "                LaplacianSharpenFilterAdapter,\n",
        "            ],\n",
        "        ]\n",
        "\n",
        "        # Randomly select one filter from each layer\n",
        "        filter_list = [random.choice(layer) for layer in filter_layers]\n",
        "\n",
        "        # Generate random hyperparameters for selected filters\n",
        "        hyperparameters = choose_random_hyperparameters(filter_list)\n",
        "\n",
        "        # Apply filters sequentially\n",
        "        for i, filter_class in enumerate(filter_list):\n",
        "            img_numpy = filter_class.apply_filter(img_numpy, hyperparameters[i])\n",
        "\n",
        "        # Convert back to PyTorch tensor (CHW format) and restore device\n",
        "        sample[\"img\"] = (\n",
        "            torch.from_numpy(img_numpy).permute(2, 0, 1).to(img_tensor.device)\n",
        "        )\n",
        "\n",
        "        return sample"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ZShdWrvA_Pg"
      },
      "source": [
        "## 6. YOLO Trainer Class\n",
        "Wrapper class for training and testing YOLO models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PR9Fo92_U6RP"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "\n",
        "class YOLOTrainer:\n",
        "    \"\"\"\n",
        "    YOLO training manager supporting multiple versions (v3, v5, v8, etc.).\n",
        "\n",
        "    Provides methods for:\n",
        "    - Loading pretrained models\n",
        "    - Training with custom parameters\n",
        "    - Testing and evaluation\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model_size: str = \"s\", model_version: str = \"v8\"):\n",
        "        \"\"\"\n",
        "        Initialize YOLO trainer.\n",
        "\n",
        "        Args:\n",
        "            model_size: Model size ('n', 's', 'm', 'l', 'x')\n",
        "                       For YOLOv3: 'n'=tiny, 'u'=standard, 'l'/'x'=spp\n",
        "            model_version: Model version ('v3', 'v5', 'v8', etc.)\n",
        "        \"\"\"\n",
        "        self.model_size = model_size\n",
        "        self.model_version = model_version\n",
        "        self.model = None\n",
        "\n",
        "    def load_pretrained(self):\n",
        "        \"\"\"Load pretrained COCO weights.\"\"\"\n",
        "        if self.model_version == \"v3\":\n",
        "            # YOLOv3 Ultralytics: yolov3u.pt, yolov3-tinyu.pt, yolov3-sppu.pt\n",
        "            size_map = {\"tiny\": \"-tiny\", \"spp\": \"-spp\", \"u\": \"\"}\n",
        "            suffix = size_map.get(self.model_size, \"\")\n",
        "            model_name = f\"yolov3{suffix}u.pt\"\n",
        "        else:\n",
        "            # For v5, v8, v9, v10, v11\n",
        "            model_name = f\"yolo{self.model_version}{self.model_size}.pt\"\n",
        "\n",
        "        self.model = YOLO(model_name)\n",
        "        print(f\"âœ“ Pretrained model loaded: {model_name}\")\n",
        "\n",
        "    def train(\n",
        "        self,\n",
        "        data_yaml: str,\n",
        "        epochs=100,\n",
        "        img_size=640,\n",
        "        batch_size=16,\n",
        "        lr0=0.01,\n",
        "        optimizer=\"SGD\",\n",
        "        device=0,\n",
        "        patience=100,\n",
        "        name=\"exp\",\n",
        "        resume=False,\n",
        "        momentum=0.9,\n",
        "        **kwargs,\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Train YOLO model with paper-recommended parameters.\n",
        "\n",
        "        Default settings follow YOLOv3 paper (Section 6.1):\n",
        "        - epochs: 100\n",
        "        - lr0: 0.01 (initial learning rate)\n",
        "        - optimizer: SGD\n",
        "        - momentum: 0.9\n",
        "\n",
        "        Args:\n",
        "            data_yaml: Path to YAML configuration file\n",
        "            epochs: Number of training epochs\n",
        "            img_size: Input image size\n",
        "            batch_size: Batch size\n",
        "            lr0: Initial learning rate\n",
        "            optimizer: Optimizer type ('SGD', 'Adam', etc.)\n",
        "            device: GPU device ID or 'cpu'\n",
        "            patience: Early stopping patience\n",
        "            name: Experiment name\n",
        "            resume: Resume from checkpoint\n",
        "            momentum: SGD momentum\n",
        "            **kwargs: Additional training arguments\n",
        "\n",
        "        Returns:\n",
        "            dict: Training results with best model path\n",
        "        \"\"\"\n",
        "        self.load_pretrained()\n",
        "\n",
        "        # Training parameters (paper-based defaults + no default augmentation)\n",
        "        train_params = {\n",
        "            \"data\": data_yaml,\n",
        "            \"epochs\": epochs,\n",
        "            \"imgsz\": img_size,\n",
        "            \"batch\": batch_size,\n",
        "            \"lr0\": lr0,\n",
        "            \"optimizer\": optimizer,\n",
        "            \"device\": device,\n",
        "            \"patience\": patience,\n",
        "            \"momentum\": momentum,\n",
        "            \"save\": True,\n",
        "            \"exist_ok\": True,\n",
        "            \"pretrained\": True,\n",
        "            \"verbose\": True,\n",
        "            \"project\": f\"yolo{self.model_version}_finetuning\",\n",
        "            \"name\": name,\n",
        "            \"resume\": resume,\n",
        "            # Disable default data augmentation for controlled experiments\n",
        "            \"hsv_h\": 0.0,  # Hue augmentation\n",
        "            \"hsv_s\": 0.0,  # Saturation augmentation\n",
        "            \"hsv_v\": 0.0,  # Value augmentation\n",
        "            \"degrees\": 0.0,  # Rotation\n",
        "            \"translate\": 0.0,  # Translation\n",
        "            \"scale\": 0.0,  # Scaling\n",
        "            \"shear\": 0.0,  # Shear\n",
        "            \"perspective\": 0.0,  # Perspective transform\n",
        "            \"flipud\": 0.0,  # Vertical flip\n",
        "            \"fliplr\": 0.0,  # Horizontal flip\n",
        "            \"mosaic\": 0.0,  # Mosaic augmentation\n",
        "            \"mixup\": 0.0,  # Mixup augmentation\n",
        "            \"copy_paste\": 0.0,  # Copy-paste augmentation\n",
        "            **kwargs,\n",
        "        }\n",
        "\n",
        "        print(\"\\n\" + \"=\" * 60)\n",
        "        print(f\"Starting training: YOLO{self.model_version}{self.model_size}\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        train_results = self.model.train(**train_params)\n",
        "\n",
        "        # Get best model path from training results\n",
        "        best_path = train_results.save_dir / \"weights\" / \"best.pt\"\n",
        "\n",
        "        print(f\"\\nâœ“ Training complete! Best model saved to: {best_path}\")\n",
        "\n",
        "        return {\"best_path\": str(best_path), \"train_results\": train_results}\n",
        "\n",
        "    def test(self, data_yaml: str, best_path: str, conf=0.25, iou=0.45, **kwargs):\n",
        "        \"\"\"\n",
        "        Test the best model on test set.\n",
        "\n",
        "        Args:\n",
        "            data_yaml: Path to YAML configuration file\n",
        "            best_path: Path to best.pt from training\n",
        "            conf: Confidence threshold\n",
        "            iou: IoU threshold for NMS\n",
        "            **kwargs: Additional validation arguments\n",
        "\n",
        "        Returns:\n",
        "            dict: Test metrics (precision, recall, mAP50, mAP50-95)\n",
        "        \"\"\"\n",
        "        # Load best model\n",
        "        self.model = YOLO(best_path)\n",
        "        print(f\"âœ“ Loaded best model: {best_path}\")\n",
        "\n",
        "        # Run test evaluation\n",
        "        test_results = self.model.val(\n",
        "            data=data_yaml, split=\"test\", conf=conf, iou=iou, **kwargs\n",
        "        )\n",
        "\n",
        "        # Display results\n",
        "        print(\"\\n\" + \"=\" * 60)\n",
        "        print(\"TEST METRICS\")\n",
        "        print(\"=\" * 60)\n",
        "        print(f\"mAP50        : {test_results.box.map50:.4f}\")\n",
        "        print(f\"mAP50-95     : {test_results.box.map:.4f}\")\n",
        "        print(f\"Precision    : {test_results.box.mp:.4f}\")\n",
        "        print(f\"Recall       : {test_results.box.mr:.4f}\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        metrics = {\n",
        "            \"precision\": float(test_results.box.mp),\n",
        "            \"recall\": float(test_results.box.mr),\n",
        "            \"mAP50\": float(test_results.box.map50),\n",
        "            \"mAP50_95\": float(test_results.box.map),\n",
        "        }\n",
        "\n",
        "        return {\"metrics\": metrics}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FecbsFrrtVsP"
      },
      "source": [
        "## 7. Apply Custom Data Augmentation\n",
        "Inject custom dataset class into YOLO training pipeline (if enabled)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Train and Test YOLO\n",
        "Execute the complete training and testing workflow."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6sxlsco21zCj"
      },
      "outputs": [],
      "source": [
        "if data_augmentation.value:\n",
        "    print(\"âœ“ Custom data augmentation enabled\")\n",
        "\n",
        "    from ultralytics.data.build import build_yolo_dataset\n",
        "\n",
        "    # Save reference to original builder\n",
        "    original_build = build_yolo_dataset\n",
        "\n",
        "    def custom_build_yolo_dataset(\n",
        "        cfg,\n",
        "        img_path,\n",
        "        batch,\n",
        "        data,\n",
        "        mode=\"train\",\n",
        "        rect=False,\n",
        "        stride=32,\n",
        "        multi_modal=False,\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Custom dataset builder that injects filter-based augmentation for training.\n",
        "        \"\"\"\n",
        "        dataset = original_build(\n",
        "            cfg, img_path, batch, data, mode, rect, stride, multi_modal\n",
        "        )\n",
        "\n",
        "        # Replace dataset class with augmented version for training only\n",
        "        if mode == \"train\":\n",
        "            dataset.__class__ = YOLODatasetCustomDA\n",
        "\n",
        "        return dataset\n",
        "\n",
        "    # Monkey-patch Ultralytics to use custom dataset builder\n",
        "    import ultralytics.data.build\n",
        "    import ultralytics.models.yolo.detect.train\n",
        "\n",
        "    ultralytics.data.build.build_yolo_dataset = custom_build_yolo_dataset\n",
        "    ultralytics.models.yolo.detect.train.build_yolo_dataset = custom_build_yolo_dataset\n",
        "\n",
        "    print(\"âœ“ Custom dataset builder injected into training pipeline\")\n",
        "else:\n",
        "    print(\"â—‹ Custom data augmentation disabled (default YOLO augmentation)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ZfY_dPXp_pTM",
        "outputId": "6b03ef11-631d-4501-a14c-8ba0c59eb6af"
      },
      "outputs": [],
      "source": [
        "# Initialize trainer\n",
        "trainer = YOLOTrainer(model_size=\"u\", model_version=\"v3\")\n",
        "\n",
        "# Train model\n",
        "print(\"Starting training phase...\")\n",
        "results = trainer.train(\n",
        "    data_yaml=str(config_path),\n",
        "    epochs=100,\n",
        "    batch_size=16,\n",
        "    device=\"0\",  # Use GPU 0, or \"cpu\" for CPU training\n",
        ")\n",
        "\n",
        "print(f\"\\nTraining results: {results}\")\n",
        "\n",
        "# Test on test set with best model\n",
        "print(\"\\n\\nStarting testing phase...\")\n",
        "test_results = trainer.test(\n",
        "    data_yaml=str(config_path), best_path=results[\"best_path\"], device=\"0\"\n",
        ")\n",
        "\n",
        "print(f\"\\nTest metrics: {test_results['metrics']}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "databundleVersionId": 10766778,
          "datasetId": 6466272,
          "sourceId": 10446385,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 31260,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "siv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
